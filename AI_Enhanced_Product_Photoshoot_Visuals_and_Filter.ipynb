{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_cv"
      ],
      "metadata": {
        "id": "a2FoFeVKxatn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76acf419-3ffc-45c9-86c3-172ce82b596a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_cv\n",
            "  Downloading keras_cv-0.8.2-py3-none-any.whl (613 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/613.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/613.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m604.2/613.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
            "Collecting keras-core (from keras_cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Collecting namex (from keras-core->keras_cv)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.3.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.63.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras_cv\n",
            "Successfully installed keras-core-0.1.7 keras_cv-0.8.2 namex-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras_cv.models import StableDiffusion\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Cm8jFPjXl4RQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05e61d2-6169-40fd-b79e-9bdee22153b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Stable Diffusion model\n",
        "model_diffusion = StableDiffusion(img_width=512, img_height=512)"
      ],
      "metadata": {
        "id": "YhZAekJIn1IL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b080f70-ad5d-4df9-9678-4a95065bbdd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained MobileNetV2 model for image classification\n",
        "model_classification = tf.keras.applications.MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "eCL_-v5Tn29F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d714c0-bb9c-4aef-bdef-835a2c8cb7a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, batch_size=3):\n",
        "    # Generate images based on the prompt\n",
        "    images = model_diffusion.text_to_image(prompt, batch_size=batch_size)\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "i8Bfu0EDzP7F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    # Plot the generated images\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i, image in enumerate(images):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "abgatRkcoAsx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images):\n",
        "    # Resize images to match the input shape expected by MobileNetV2 (224x224)\n",
        "    resized_images = [tf.image.resize(img, (224, 224)) for img in images]\n",
        "    # Preprocess images for MobileNetV2\n",
        "    preprocessed_images = [tf.keras.applications.mobilenet_v2.preprocess_input(img) for img in resized_images]\n",
        "    preprocessed_images = np.array(preprocessed_images)\n",
        "    return preprocessed_images"
      ],
      "metadata": {
        "id": "uCBde93eoGzq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_images(images, model):\n",
        "    # Preprocess and resize images\n",
        "    preprocessed_images = preprocess_images(images)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(preprocessed_images)\n",
        "\n",
        "    # Decode predictions\n",
        "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions)\n",
        "\n",
        "    return decoded_predictions"
      ],
      "metadata": {
        "id": "6dKfqn-LoKir"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_non_relevant_images(images, model):\n",
        "    # Implement a binary classifier for demonstration\n",
        "\n",
        "    relevant_images = []\n",
        "    for image in images:\n",
        "        # Use the MobileNetV2 model for binary classification\n",
        "        preprocessed_image = preprocess_images([image])\n",
        "        prediction = model.predict(preprocessed_image)\n",
        "\n",
        "        # Modify this condition based on your binary classification model\n",
        "        if prediction[0][0] > 0.5:\n",
        "            relevant_images.append(image)\n",
        "\n",
        "    return relevant_images"
      ],
      "metadata": {
        "id": "PIMswVq02dEv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "prompt = \"Headphones\"\n",
        "batch_size = 3"
      ],
      "metadata": {
        "id": "Qk-J10SDoNO7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and plot images\n",
        "generated_images = generate_images(prompt, batch_size=batch_size)\n",
        "relevant_images = filter_non_relevant_images(generated_images, model_classification)\n",
        "plot_images(generated_images)"
      ],
      "metadata": {
        "id": "dWsxdlscoQvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b1e196-2e1f-4b66-ebab-4c0bb3df36df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 9s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 61s 0us/step\n",
            "26/50 [==============>...............] - ETA: 49:26"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify generated images\n",
        "classifications = classify_images(generated_images, model_classification)"
      ],
      "metadata": {
        "id": "Vo2wRgB4oU0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the classifications\n",
        "for i, img_class in enumerate(classifications):\n",
        "    print(f\"Image {i + 1} classification:\")\n",
        "    for j, (imagenet_id, label, score) in enumerate(img_class):\n",
        "        print(f\"{j + 1}: {label} ({score:.2f})\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "tjBgwdFaoXUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oinZ_K1q8nXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}